{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/r3dmaohong/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "from scipy.misc import imread, imsave, imresize\n",
    "from natsort import natsorted\n",
    "\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"data/julia\"\n",
    "\n",
    "img_height, img_width = 32, 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/r3dmaohong/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:21: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "/Users/r3dmaohong/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:24: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n",
      "/Users/r3dmaohong/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:33: DeprecationWarning: `imsave` is deprecated!\n",
      "`imsave` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imwrite`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Before:  (6283, 32, 32)\n",
      "train After:  (6283, 32, 32, 1)\n",
      "test Before:  (6220, 32, 32)\n",
      "test After:  (6220, 32, 32, 1)\n"
     ]
    }
   ],
   "source": [
    "# save path for images after processed\n",
    "suffix = \"Preproc\"\n",
    "trainDataPath = path + \"/train\" + suffix\n",
    "testDataPath = path + \"/test\" + suffix\n",
    "\n",
    "if not os.path.exists(trainDataPath):\n",
    "    os.makedirs(trainDataPath)\n",
    "if not os.path.exists(testDataPath):\n",
    "    os.makedirs(testDataPath)\n",
    "    \n",
    "\n",
    "for datasetType in [\"train\",\"test\"]:\n",
    "    # sort files\n",
    "    imgFiles = natsorted(glob.glob(path + \"/\" + datasetType + \"/*\"))\n",
    "    \n",
    "    # save imgs\n",
    "    imgData = np.zeros((len(imgFiles), img_height, img_width))\n",
    "    \n",
    "    for i, imgFilePath in enumerate(imgFiles):\n",
    "        # True: one channel\n",
    "        img = imread(imgFilePath, True) \n",
    "        \n",
    "        # image resizing\n",
    "        imgResized = imresize(img, (img_height, img_width))\n",
    "        \n",
    "        imgData[i] = imgResized\n",
    "        \n",
    "        # save\n",
    "        filename = os.path.basename(imgFilePath)\n",
    "        filenameDotSplit = filename.split(\".\")\n",
    "        newFilename = str(int(filenameDotSplit[0])).zfill(5) + \".\" + filenameDotSplit[-1].lower()\n",
    "        newFilepath = path + \"/\" + datasetType + suffix + \"/\" + newFilename\n",
    "        imsave(newFilepath, imgResized)\n",
    "    \n",
    "    # generate a new dimension for channel\n",
    "    print(datasetType, \"Before: \", imgData.shape)\n",
    "    imgData = imgData[:,:,:,np.newaxis]\n",
    "    print(datasetType, \"After: \", imgData.shape)\n",
    "    \n",
    "    # 進行資料(pixel值)標準化\n",
    "    imgData = imgData.astype('float32')/255\n",
    "    \n",
    "    # 以numpy物件將圖像轉換後的ndarray物件保存在檔案系統中\n",
    "    np.save(path + \"/\" + datasetType + suffix + \".npy\", imgData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label conversion\n",
    "# 0-9, a-z, A-Z\n",
    "# 62\n",
    "\n",
    "def label2int(ch):\n",
    "    # Return the Unicode code point for a one-character string.\n",
    "    asciiVal = ord(ch)\n",
    "    if(asciiVal<=57): #0-9\n",
    "        asciiVal-=48\n",
    "    elif(asciiVal<=90): #A-Z\n",
    "        asciiVal-=55\n",
    "    else: #a-z\n",
    "        asciiVal-=61\n",
    "    return asciiVal\n",
    "    \n",
    "def int2label(i):\n",
    "    if(i<=9): #0-9\n",
    "        i+=48\n",
    "    elif(i<=35): #A-Z\n",
    "        i+=55\n",
    "    else: #a-z\n",
    "        i+=61\n",
    "    # Return a Unicode string of one character with ordinal i\n",
    "    return chr(i)\n",
    "\n",
    "# only retain the label col\n",
    "y_train = pd.read_csv(path + \"/trainLabels.csv\").values[:,1]\n",
    "\n",
    "# one hot encoding\n",
    "Y_train = np.zeros((y_train.shape[0], 62))\n",
    "\n",
    "for i in range(y_train.shape[0]):\n",
    "    Y_train[i][label2int(y_train[i])] = 1\n",
    "\n",
    "np.save(path + \"/\" + \"labelsPreproc.npy\", Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "batch_size = 128\n",
    "# 0-9, a-z, A-Z\n",
    "nb_classes = 62\n",
    "nb_epoch = 300\n",
    "\n",
    "img_height, img_width = 32, 32\n",
    "\n",
    "# training data and lebels after processed\n",
    "X_train_all = np.load(path+\"/trainPreproc.npy\")\n",
    "Y_train_all = np.load(path+\"/labelsPreproc.npy\")\n",
    "\n",
    "\n",
    "X_train, X_val, Y_train, Y_val = \\\n",
    "    train_test_split(X_train_all, Y_train_all, test_size=0.25, stratify\n",
    "                     =np.argmax(Y_train_all, axis=1))\n",
    "\n",
    "# data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range = 20,\n",
    "    width_shift_range = 0.15,\n",
    "    height_shift_range = 0.15,\n",
    "    shear_range = 0.4,\n",
    "    zoom_range = 0.3,                    \n",
    "    channel_shift_range = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 128)       1280      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 16, 256)       295168    \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 16, 16, 256)       590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 8, 8, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              33558528  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 62)                254014    \n",
      "=================================================================\n",
      "Total params: 57,527,742\n",
      "Trainable params: 57,527,742\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Convolution2D(128,(3, 3), padding='same', kernel_initializer='he_normal', activation='relu', \n",
    "                        input_shape=(img_height, img_width, 1)))\n",
    "\n",
    "model.add(Convolution2D(128,(3, 3), padding='same', kernel_initializer='he_normal', activation='relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Convolution2D(256,(3, 3), padding='same', kernel_initializer='he_normal', activation='relu'))\n",
    "model.add(Convolution2D(256,(3, 3), padding='same', kernel_initializer='he_normal', activation='relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Convolution2D(512,(3, 3), padding='same', kernel_initializer='he_normal', activation='relu'))\n",
    "model.add(Convolution2D(512,(3, 3), padding='same', kernel_initializer='he_normal', activation='relu'))\n",
    "model.add(Convolution2D(512,(3, 3), padding='same', kernel_initializer='he_normal', activation='relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(4096, kernel_initializer='he_normal', activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(4096, kernel_initializer='he_normal', activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(nb_classes, kernel_initializer='he_normal', activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "AdaDelta\n",
      "==================================================\n",
      "Train on 4712 samples, validate on 1571 samples\n",
      "Epoch 1/20\n",
      "4712/4712 [==============================] - 820s 174ms/step - loss: 14.7871 - acc: 0.0558 - val_loss: 15.2050 - val_acc: 0.0567\n",
      "Epoch 2/20\n",
      "4712/4712 [==============================] - 858s 182ms/step - loss: 15.2014 - acc: 0.0569 - val_loss: 15.2050 - val_acc: 0.0567\n",
      "Epoch 3/20\n",
      "4712/4712 [==============================] - 860s 182ms/step - loss: 15.2014 - acc: 0.0569 - val_loss: 15.2050 - val_acc: 0.0567\n",
      "Epoch 4/20\n",
      "4712/4712 [==============================] - 874s 185ms/step - loss: 15.2014 - acc: 0.0569 - val_loss: 15.2050 - val_acc: 0.0567\n",
      "Epoch 5/20\n",
      "4712/4712 [==============================] - 940s 200ms/step - loss: 15.2014 - acc: 0.0569 - val_loss: 15.2050 - val_acc: 0.0567\n",
      "Epoch 6/20\n",
      "4712/4712 [==============================] - 849s 180ms/step - loss: 15.2014 - acc: 0.0569 - val_loss: 15.2050 - val_acc: 0.0567\n",
      "Epoch 7/20\n",
      "4712/4712 [==============================] - 838s 178ms/step - loss: 15.2014 - acc: 0.0569 - val_loss: 15.2050 - val_acc: 0.0567\n",
      "Epoch 8/20\n",
      "4712/4712 [==============================] - 1220s 259ms/step - loss: 15.2014 - acc: 0.0569 - val_loss: 15.2050 - val_acc: 0.0567\n",
      "Epoch 9/20\n",
      "4712/4712 [==============================] - 771s 164ms/step - loss: 15.2014 - acc: 0.0569 - val_loss: 15.2050 - val_acc: 0.0567\n",
      "Epoch 10/20\n",
      "4712/4712 [==============================] - 769s 163ms/step - loss: 15.2014 - acc: 0.0569 - val_loss: 15.2050 - val_acc: 0.0567\n",
      "Epoch 11/20\n",
      "4712/4712 [==============================] - 771s 164ms/step - loss: 15.2014 - acc: 0.0569 - val_loss: 15.2050 - val_acc: 0.0567\n",
      "Epoch 12/20\n",
      "4712/4712 [==============================] - 768s 163ms/step - loss: 15.2014 - acc: 0.0569 - val_loss: 15.2050 - val_acc: 0.0567\n",
      "Epoch 13/20\n",
      "4712/4712 [==============================] - 769s 163ms/step - loss: 15.2014 - acc: 0.0569 - val_loss: 15.2050 - val_acc: 0.0567\n",
      "Epoch 14/20\n",
      "4712/4712 [==============================] - 768s 163ms/step - loss: 15.2014 - acc: 0.0569 - val_loss: 15.2050 - val_acc: 0.0567\n",
      "Epoch 15/20\n",
      "4712/4712 [==============================] - 794s 169ms/step - loss: 15.2014 - acc: 0.0569 - val_loss: 15.2050 - val_acc: 0.0567\n",
      "Epoch 16/20\n",
      "4712/4712 [==============================] - 842s 179ms/step - loss: 15.2014 - acc: 0.0569 - val_loss: 15.2050 - val_acc: 0.0567\n",
      "Epoch 17/20\n",
      "4712/4712 [==============================] - 945s 200ms/step - loss: 15.2014 - acc: 0.0569 - val_loss: 15.2050 - val_acc: 0.0567\n",
      "Epoch 18/20\n",
      "4712/4712 [==============================] - 804s 171ms/step - loss: 15.2014 - acc: 0.0569 - val_loss: 15.2050 - val_acc: 0.0567\n",
      "Epoch 19/20\n",
      "4712/4712 [==============================] - 1030s 219ms/step - loss: 15.2014 - acc: 0.0569 - val_loss: 15.2050 - val_acc: 0.0567\n",
      "Epoch 20/20\n",
      "4712/4712 [==============================] - 1677s 356ms/step - loss: 15.2014 - acc: 0.0569 - val_loss: 15.2050 - val_acc: 0.0567\n",
      "==================================================\n",
      "AdaMax\n",
      "==================================================\n",
      "Epoch 1/300\n",
      "36/36 [============================>.] - ETA: 33s - loss: 15.1922 - acc: 0.0574 Epoch 00001: val_acc improved from -inf to 0.05665, saving model to best.kerasModelWeights\n",
      "37/36 [==============================] - 1671s 45s/step - loss: 15.2036 - acc: 0.0567 - val_loss: 15.2050 - val_acc: 0.0567\n",
      "Epoch 2/300\n",
      "36/36 [============================>.] - ETA: 35s - loss: 15.1952 - acc: 0.0573 Epoch 00002: val_acc did not improve\n",
      "37/36 [==============================] - 1791s 48s/step - loss: 15.1998 - acc: 0.0570 - val_loss: 15.2050 - val_acc: 0.0567\n",
      "Epoch 3/300\n",
      "36/36 [============================>.] - ETA: 33s - loss: 15.1847 - acc: 0.0579 Epoch 00003: val_acc did not improve\n",
      "37/36 [==============================] - 1648s 45s/step - loss: 15.1998 - acc: 0.0570 - val_loss: 15.2050 - val_acc: 0.0567\n",
      "Epoch 4/300\n",
      "36/36 [============================>.] - ETA: 31s - loss: 15.1957 - acc: 0.0572 Epoch 00004: val_acc did not improve\n",
      "37/36 [==============================] - 1570s 42s/step - loss: 15.2036 - acc: 0.0567 - val_loss: 15.2050 - val_acc: 0.0567\n",
      "Epoch 5/300\n",
      "36/36 [============================>.] - ETA: 33s - loss: 15.1944 - acc: 0.0573 Epoch 00005: val_acc did not improve\n",
      "37/36 [==============================] - 1652s 45s/step - loss: 15.1990 - acc: 0.0570 - val_loss: 15.2050 - val_acc: 0.0567\n",
      "Epoch 6/300\n",
      "36/36 [============================>.] - ETA: 20:34 - loss: 15.1871 - acc: 0.0578Epoch 00006: val_acc did not improve\n",
      "37/36 [==============================] - 54926s 1484s/step - loss: 15.2021 - acc: 0.0568 - val_loss: 15.2050 - val_acc: 0.0567\n",
      "Epoch 7/300\n",
      "36/36 [============================>.] - ETA: 36s - loss: 15.1925 - acc: 0.0574 Epoch 00007: val_acc did not improve\n",
      "37/36 [==============================] - 1829s 49s/step - loss: 15.2005 - acc: 0.0569 - val_loss: 15.2050 - val_acc: 0.0567\n",
      "Epoch 8/300\n",
      "36/36 [============================>.] - ETA: 36s - loss: 15.2035 - acc: 0.0567 Epoch 00008: val_acc did not improve\n",
      "37/36 [==============================] - 1807s 49s/step - loss: 15.2044 - acc: 0.0567 - val_loss: 15.2050 - val_acc: 0.0567\n",
      "Epoch 9/300\n",
      "11/36 [=======>......................] - ETA: 18:48 - loss: 15.2516 - acc: 0.0538"
     ]
    }
   ],
   "source": [
    "# use adadelta to be the first part of the training because adamax will be stucked.\n",
    "print(\"=\"*50)\n",
    "print(\"AdaDelta\")\n",
    "print(\"=\"*50)\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer='adadelta',  \n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(X_train, Y_train, batch_size=batch_size,\n",
    "                    epochs=20, \n",
    "                    validation_data=(X_val, Y_val),\n",
    "                    verbose=1)\n",
    "print(\"=\"*50)\n",
    "print(\"AdaMax\")\n",
    "print(\"=\"*50)\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer='adamax',  \n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "# save better validation accuracy model\n",
    "saveBestModel = ModelCheckpoint(\"best.kerasModelWeights\", monitor='val_acc', verbose=1, \\\n",
    "                                save_best_only=True, save_weights_only=True)\n",
    "\n",
    "# data augmentation\n",
    "history = model.fit_generator(datagen.flow(X_train, Y_train, batch_size=batch_size),\n",
    "                    steps_per_epoch=len(X_train)/batch_size,\n",
    "                    epochs=nb_epoch, \n",
    "                    validation_data=(X_val, Y_val),\n",
    "                    callbacks=[saveBestModel],\n",
    "                    verbose=1)\n",
    "\n",
    "# load best validation accuracy model\n",
    "model.load_weights(\"best.kerasModelWeights\")\n",
    "\n",
    "# load test data\n",
    "X_test = np.load(path+\"/testPreproc.npy\")\n",
    "\n",
    "# predict\n",
    "Y_test_pred = model.predict_classes(X_test)\n",
    "\n",
    "# int to label\n",
    "vInt2label = np.vectorize(int2label)\n",
    "Y_test_pred = vInt2label(Y_test_pred) \n",
    "\n",
    "\n",
    "# save predict output\n",
    "np.savetxt(path+\"/jular_pred\" + \".csv\", np.c_[range(6284,len(Y_test_pred)+6284),Y_test_pred],\\\n",
    "           delimiter=',', header = 'ID,Class', comments = '', fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
